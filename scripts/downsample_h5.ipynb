{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2529366/1261760727.py:9: DeprecationWarning: Please import `zoom` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.interpolation import zoom\n"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import cv2\n",
    "import math\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sr_3dunet.utils.data_utils import random_crop_3d, random_crop_2d, augment_3d, augment_2d, preprocess, get_projection, get_rotated_img, crop_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inference: 100%|██████████| 4488/4488 [06:23<00:00, 11.71h5_img/s]\n",
      "inference: 100%|██████████| 4488/4488 [13:10<00:00,  9.11h5_img/s]"
     ]
    }
   ],
   "source": [
    "ims_path = '/share/home/wangwb/workspace/sr_3dunet/datasets/NISSL/RESIN_CJ4ROI1_NISSL_piece64/output_res0.h5'\n",
    "out_ims_path = '/share/home/wangwb/workspace/sr_3dunet/datasets/NISSL/RESIN_CJ4ROI1_NISSL_piece64/output_res1.h5'\n",
    "\n",
    "h5 = h5py.File(ims_path, 'r')\n",
    "img_total = h5['DataSet']['ResolutionLevel 0']['TimePoint 0']['Channel 0']['Data']\n",
    "out_h5_dir = 'DataSet/ResolutionLevel 1/TimePoint 0/Channel 0/Data'\n",
    "\n",
    "step_size = 256\n",
    "downscale_factor = 2\n",
    "\n",
    "with h5py.File(out_ims_path, 'w') as f:\n",
    "    f.create_dataset(out_h5_dir, shape=[img_total.shape[0]//downscale_factor, img_total.shape[1]//downscale_factor, img_total.shape[2]//downscale_factor], chunks=(1, 128, 128), dtype=img_total.dtype)\n",
    "\n",
    "len1 = math.ceil(img_total.shape[0]/step_size)\n",
    "len2 = math.ceil(img_total.shape[1]/step_size)\n",
    "len3 = math.ceil(img_total.shape[2]/step_size)\n",
    "pbar1 = tqdm(total=len1*len2*len3, unit='h5_img', desc='inference')\n",
    "\n",
    "for start_h in range(0, img_total.shape[0], step_size):\n",
    "    end_h = img_total.shape[0] if start_h+step_size>img_total.shape[0] else start_h+step_size\n",
    "    for start_w in range(0, img_total.shape[1], step_size):\n",
    "        end_w = img_total.shape[1] if start_w+step_size>img_total.shape[1] else start_w+step_size\n",
    "        for start_d in range(0, img_total.shape[2], step_size):\n",
    "            end_d = img_total.shape[2] if start_d+step_size>img_total.shape[2] else start_d+step_size\n",
    "            \n",
    "            new_shape = ((end_h-start_h) // downscale_factor,\n",
    "             (end_w-start_w) // downscale_factor,\n",
    "             (end_d-start_d) // downscale_factor)\n",
    "            \n",
    "            # img_total[start_h:end_h, start_w:end_w, start_d:end_d].resize(new_shape, resample=Image.BICUBIC)\n",
    "            new_img = zoom(img_total[start_h:end_h, start_w:end_w, start_d:end_d], zoom = 1/downscale_factor, order=1)\n",
    "\n",
    "            with h5py.File(out_ims_path, 'r+') as f:\n",
    "                f[out_h5_dir][start_h//downscale_factor:end_h//downscale_factor, start_w//downscale_factor:end_w//downscale_factor, start_d//downscale_factor:end_d//downscale_factor] = new_img\n",
    "\n",
    "            pbar1.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inference:  74%|███████▎  | 3308/4488 [06:52<02:27,  8.01h5_img/s]\n"
     ]
    }
   ],
   "source": [
    "ims_path = '/share/home/wangwb/workspace/sr_3dunet/datasets/NISSL/RESIN_CJ4ROI1_NISSL_piece64/output_res0.h5'\n",
    "out_ims_path = '/share/home/wangwb/workspace/sr_3dunet/datasets/NISSL/RESIN_CJ4ROI1_NISSL_piece64/output_res2.h5'\n",
    "\n",
    "h5 = h5py.File(ims_path, 'r')\n",
    "img_total = h5['DataSet']['ResolutionLevel 0']['TimePoint 0']['Channel 0']['Data']\n",
    "out_h5_dir = 'DataSet/ResolutionLevel 2/TimePoint 0/Channel 0/Data'\n",
    "\n",
    "step_size = 256\n",
    "downscale_factor = 4\n",
    "\n",
    "with h5py.File(out_ims_path, 'w') as f:\n",
    "    f.create_dataset(out_h5_dir, shape=[img_total.shape[0]//downscale_factor, img_total.shape[1]//downscale_factor, img_total.shape[2]//downscale_factor], chunks=(1, 128, 128), dtype=img_total.dtype)\n",
    "\n",
    "len1 = math.ceil(img_total.shape[0]/step_size)\n",
    "len2 = math.ceil(img_total.shape[1]/step_size)\n",
    "len3 = math.ceil(img_total.shape[2]/step_size)\n",
    "pbar1 = tqdm(total=len1*len2*len3, unit='h5_img', desc='inference')\n",
    "\n",
    "for start_h in range(0, img_total.shape[0], step_size):\n",
    "    end_h = img_total.shape[0] if start_h+step_size>img_total.shape[0] else start_h+step_size\n",
    "    for start_w in range(0, img_total.shape[1], step_size):\n",
    "        end_w = img_total.shape[1] if start_w+step_size>img_total.shape[1] else start_w+step_size\n",
    "        for start_d in range(0, img_total.shape[2], step_size):\n",
    "            end_d = img_total.shape[2] if start_d+step_size>img_total.shape[2] else start_d+step_size\n",
    "            \n",
    "            new_shape = ((end_h-start_h) // downscale_factor,\n",
    "             (end_w-start_w) // downscale_factor,\n",
    "             (end_d-start_d) // downscale_factor)\n",
    "            \n",
    "            # img_total[start_h:end_h, start_w:end_w, start_d:end_d].resize(new_shape, resample=Image.BICUBIC)\n",
    "            new_img = zoom(img_total[start_h:end_h, start_w:end_w, start_d:end_d], zoom = 1/downscale_factor, order=1)\n",
    "\n",
    "            with h5py.File(out_ims_path, 'r+') as f:\n",
    "                f[out_h5_dir][start_h//downscale_factor:end_h//downscale_factor, start_w//downscale_factor:end_w//downscale_factor, start_d//downscale_factor:end_d//downscale_factor] = new_img\n",
    "\n",
    "            pbar1.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims_path = '/share/home/wangwb/workspace/sr_3dunet/datasets/NISSL/CJ4ROI2_out_h5/output_res0.h5'\n",
    "out_ims_path = '/share/home/wangwb/workspace/sr_3dunet/datasets/NISSL/CJ4ROI2_out_h5/output_res2.h5'\n",
    "\n",
    "h5 = h5py.File(ims_path, 'r')\n",
    "img_total = h5['DataSet']['ResolutionLevel 0']['TimePoint 0']['Channel 0']['Data']\n",
    "out_h5_dir = 'DataSet/ResolutionLevel 2/TimePoint 0/Channel 0/Data'\n",
    "\n",
    "step_size = 256\n",
    "downscale_factor = 4\n",
    "\n",
    "with h5py.File(out_ims_path, 'w') as f:\n",
    "    f.create_dataset(out_h5_dir, shape=[img_total.shape[0]//downscale_factor, img_total.shape[1]//downscale_factor, img_total.shape[2]//downscale_factor], chunks=(1, 128, 128), dtype=img_total.dtype)\n",
    "\n",
    "len1 = math.ceil(img_total.shape[0]/step_size)\n",
    "len2 = math.ceil(img_total.shape[1]/step_size)\n",
    "len3 = math.ceil(img_total.shape[2]/step_size)\n",
    "pbar1 = tqdm(total=len1*len2*len3, unit='h5_img', desc='inference')\n",
    "\n",
    "for start_h in range(0, img_total.shape[0], step_size):\n",
    "    end_h = img_total.shape[0] if start_h+step_size>img_total.shape[0] else start_h+step_size\n",
    "    for start_w in range(0, img_total.shape[1], step_size):\n",
    "        end_w = img_total.shape[1] if start_w+step_size>img_total.shape[1] else start_w+step_size\n",
    "        for start_d in range(0, img_total.shape[2], step_size):\n",
    "            end_d = img_total.shape[2] if start_d+step_size>img_total.shape[2] else start_d+step_size\n",
    "            \n",
    "            new_shape = ((end_h-start_h) // downscale_factor,\n",
    "             (end_w-start_w) // downscale_factor,\n",
    "             (end_d-start_d) // downscale_factor)\n",
    "            \n",
    "            # img_total[start_h:end_h, start_w:end_w, start_d:end_d].resize(new_shape, resample=Image.BICUBIC)\n",
    "            new_img = zoom(img_total[start_h:end_h, start_w:end_w, start_d:end_d], zoom = 1/downscale_factor, order=1)\n",
    "\n",
    "            with h5py.File(out_ims_path, 'r+') as f:\n",
    "                f[out_h5_dir][start_h//downscale_factor:end_h//downscale_factor, start_w//downscale_factor:end_w//downscale_factor, start_d//downscale_factor:end_d//downscale_factor] = new_img\n",
    "\n",
    "            pbar1.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_matrix = np.random.rand(1000, 1000, 1000)\n",
    "\n",
    "\n",
    "\n",
    "new_shape = (original_matrix.shape[0] // downscale_factor,\n",
    "             original_matrix.shape[1] // downscale_factor,\n",
    "             original_matrix.shape[2] // downscale_factor)\n",
    "\n",
    "new_matrix = np.zeros(new_shape)\n",
    "for i in range(new_shape[0]):\n",
    "    for j in range(new_shape[1]):\n",
    "        for k in range(new_shape[2]):\n",
    "            new_matrix[i, j, k] = np.mean(original_matrix[i*downscale_factor:(i+1)*downscale_factor,\n",
    "                                                          j*downscale_factor:(j+1)*downscale_factor,\n",
    "                                                          k*downscale_factor:(k+1)*downscale_factor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPCN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
